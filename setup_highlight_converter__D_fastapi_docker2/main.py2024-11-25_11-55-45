from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import Response, HTMLResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
from datetime import datetime
import json
import os
import io
from typing import List
from pathlib import Path
import urllib.parse

app = FastAPI()

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Create static directory if it doesn't exist
os.makedirs("static", exist_ok=True)

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

#def clean_filename(filename: str) -> str:
#    """Clean the filename by removing existing 'highlights' suffix if present"""
#    for suffix in ['-highlights', '_highlights',' - highlights','- highlights']:
#        if filename.endswith(suffix):
#            filename = filename[:-len(suffix)]
#    return filename

def clean_filename(filename: str) -> str:
    """
    Clean the filename by removing all variations of 'highlights.json' suffix.
    Handles various separator patterns between filename and 'highlights'.

    Args:
        filename (str): The filename to clean

    Returns:
        str: The filename with highlights suffix removed
    """
    # Common patterns for separators and spaces
    separators = [
        ' - highlights.json',
        '-highlights.json',
        '_highlights.json',
        ' _highlights.json',
        ' -- highlights.json',
        '--highlights.json',
        ' highlights.json',
        '.highlights.json',
        '- highlights.json',
        ' -highlights.json',
        '_ highlights.json',
        ' _ highlights.json',
        ' -  highlights.json',
        ' - highlights .json',  # Space before .json
        ' -highlights .json',
        ' - Highlights.json',   # Capital H
        ' -Highlights.json',
        '_Highlights.json',
        '-Highlights.json',
        ' _ Highlights.json',
        ' -- Highlights.json',
        ' --Highlights.json',
        ' Highlights.json',
        '.Highlights.json',
        '- Highlights.json',
        ' -Highlights.json',
        '_ Highlights.json',
        ' _ Highlights.json',
        ' -  Highlights.json',
        ' - Highlights .json',  # Space before .json
        ' -Highlights .json'
    ]

    # Sort by length in descending order to handle longer patterns first
    separators.sort(key=len, reverse=True)

    # Try each separator pattern
    for sep in separators:
        if filename.endswith(sep):
            return filename[:-len(sep)]

    return filename

def get_content_disposition_header(filename: str) -> str:
    """Generate Content-Disposition header with RFC 5987 encoding"""
    ascii_filename = filename.encode('ascii', 'ignore').decode()
    if ascii_filename == filename:
        return f'attachment; filename="{filename}"'
    else:
        encoded_filename = urllib.parse.quote(filename.encode('utf-8'))
        return f"attachment; filename*=UTF-8''{encoded_filename}"

def generate_output_filename(original_filename: str, is_combined: bool = False) -> str:
    """Generate standardized output filename with timestamp"""
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    if is_combined:
        return f"combined_highlights_{current_time}.csv"
    else:
        clean_name = clean_filename(original_filename) if original_filename else "converted"
       #return f"{clean_name}_highlights_{current_time}.csv"
        return f"one_highlights_{current_time}.csv"

def convert_json_to_csv(json_data: dict, filename: str) -> io.StringIO:
    """Convert JSON annotations to CSV format and return as StringIO."""
    try:
        csv_data = []
        annotations = json_data.get('annotations', [])

        for annotation in annotations:
            if annotation.get('type') != 'highlight':
                continue

            timestamp = annotation.get("timestamp", "")
            try:
                formatted_date = datetime.strptime(timestamp, "%Y-%m-%dT%H:%M:%S.%fZ").strftime("%Y-%m-%d %H:%M:%S") if timestamp else ""
            except ValueError:
                formatted_date = timestamp

            chapter = annotation.get("toc_family_titles", [""])[0]

            cleaned_title = clean_filename(filename)
            csv_data.append({
                "Highlight": annotation.get("highlighted_text", ""),
                "Title":  cleaned_title,
                "Chapter": chapter,
                "Note": annotation.get("notes", ""),
                "Location": "",
                "Date": formatted_date,
                "Style": annotation.get("style", {}).get("which", "")
            })

        df = pd.DataFrame(csv_data) if csv_data else pd.DataFrame(columns=['Highlight', 'Title', 'Chapter', 'Note', 'Location', 'Date', 'Style'])
        df = df[['Highlight', 'Title', 'Chapter', 'Note', 'Location', 'Date', 'Style']]

        output = io.StringIO()
        df.to_csv(output, index=False, encoding='utf-8-sig')
        output.seek(0)
        return output

    except Exception as e:
        raise Exception(f"Error converting JSON to CSV: {str(e)}")

@app.get("/", response_class=HTMLResponse)
async def read_root():
    with open("static/index.html", "r", encoding="utf-8") as f:
        return f.read()

@app.post("/upload/")
async def upload_files(files: List[UploadFile] = File(...)):
    try:
        all_data = []
        for file in files:
            if not file.filename.endswith('.json'):
                raise HTTPException(status_code=400, detail=f"File {file.filename} is not a JSON file")

            try:
                content = await file.read()
                json_data = json.loads(content.decode('utf-8'))
                filename = Path(file.filename).stem
                csv_io = convert_json_to_csv(json_data, filename)

                df = pd.read_csv(io.StringIO(csv_io.getvalue()), encoding='utf-8-sig')
                all_data.append(df)

            except json.JSONDecodeError:
                raise HTTPException(status_code=400, detail=f"File {file.filename} contains invalid JSON")
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Error processing file {file.filename}: {str(e)}")

        combined_df = pd.concat(all_data, ignore_index=True)
        output = io.StringIO()
        combined_df.to_csv(output, index=False, encoding='utf-8-sig')
        output.seek(0)

        # Generate output filename
        if len(files) == 1:
            # Use the original filename
           #file_stem = Path(files[0].filename).stem
           #output_filename = generate_output_filename(file_stem)
            output_filename = generate_output_filename("", is_combined=False)
        else:
            output_filename = generate_output_filename("", is_combined=True)

        content_disposition = get_content_disposition_header(output_filename)
        headers = {
            'Content-Disposition': content_disposition,
            'Access-Control-Expose-Headers': 'Content-Disposition'
        }

        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="text/csv; charset=utf-8",
            headers=headers
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=187, reload=True)

